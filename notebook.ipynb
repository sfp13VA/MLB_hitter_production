{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our MLB team wishes to improve upon our prior season's record in order to increase our chances of making a deep postseason run and winning the World Series next season.  Our offensive production was a weakness during the prior season.  We would like to use OPS to evaluate and predict the offensive production of MLB hitters.  OPS combines on-base skills (OBP or on-base percentage) with power hitting skills (slugging percentage), to measure overall offensive performace.  We will use this information to help build our roster for next season (evaluate our current under-contract players and possible trade acquisitions, as well as free agents).  Targeting hitters with a high OPS this offseason will help our team score more runs, win more games, perform better in the postseason, win a championship, and improve fan sentiment, driving revenue and profits in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is part of the Lahman Baseball database and obtained from Kaggle, compiled by author and journalist Sean Lahman.  It contains complete baseball statistics and data dating from 1871 to 2024.  We will use one of many tables, the \"batting\" table, for our purposes of evaluating and predicting offensive production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from kaggle) (3.2.1)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from kaggle) (2.10)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from kaggle) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from kaggle) (3.13.0)\n",
      "Requirement already satisfied: six>=1.10 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from kaggle) (3.4.4)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from kaggle) (1.25.10)\n",
      "Requirement already satisfied: text-unidecode in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: python-slugify in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from kaggle) (50.3.0.post20201103)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from kaggle) (4.50.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from kaggle) (2.24.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from bleach->kaggle) (20.4)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from packaging->bleach->kaggle) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "#install Kaggle API to read data in directly from the site\n",
    "\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle.json copied to: /Users/buzzardsroostimac/Documents/Flatiron/Phase_5/MLB_hitter_production/MLB_hitter_production/kaggle.json\n"
     ]
    }
   ],
   "source": [
    "# define download path and copy the file\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "downloads_path = os.path.expanduser('~/Downloads/kaggle.json')\n",
    "target_path = os.path.join(os.getcwd(), 'kaggle.json')\n",
    "\n",
    "if os.path.exists(downloads_path):\n",
    "    shutil.copy(downloads_path, target_path)\n",
    "    print(f\"kaggle.json copied to: {target_path}\")\n",
    "else:\n",
    "    print(\"kaggle.json not found in Downloads.  Donwload it first lol!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set permissions\n",
    "\n",
    "!chmod 600 kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ~/Downloads/kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"username\":\"shannonhunley\",\"key\":\"e3f14a20e8743dcdf2de9f39646fcd05\"}"
     ]
    }
   ],
   "source": [
    "# providing API token credentials\n",
    "\n",
    "!cat ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set permissions\n",
    "\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/dalyas/lahman-baseball-database\r\n",
      "License(s): CC-BY-SA-3.0\r\n"
     ]
    }
   ],
   "source": [
    "# downloading the Lahman baseball database which contains the hitting data\n",
    "\n",
    "!kaggle datasets download -d dalyas/lahman-baseball-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the data\n",
    "\n",
    "!unzip -o lahman-baseball-database.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the data, getting a look at its columns and some values\n",
    "df = pd.read_csv('lahman_1871-2024_csv/Batting.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the amount of data and columns\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the values of column 'G_old' since I'm unfamiliar with it, to see what info it provides\n",
    "\n",
    "df['G_old'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains plenty of records for modeling and includes all of the stats we need to compute our target, OPS.  We have a few null values to deal with and we have a few irrelevant columns we can remove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnecessary columns\n",
    "\n",
    "df_clean = df.drop(columns=['stint', 'teamID', 'lgID', 'G', 'G_batting', 'SB', 'CS', 'GIDP', 'G_old'])\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirming uneeded columns dropped and looking into null values\n",
    "\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at values for one of the columns containing null values\n",
    "\n",
    "df_clean['RBI'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at total nulls per column by number and percentage\n",
    "\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "print((df_clean.isnull().sum() / len(df_clean)) * 100)\n",
    "\n",
    "# look at some nulls in particular columns\n",
    "\n",
    "df_clean[df_clean['HBP'].isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain columns contain null values because some of these stats were not tracked prior to certain dates.  It makes sense to fill in zero for nulls in count-based stats.  The oldest data is not going to factor heavily in our conclusions because we are looking for data relating to current players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling null values with 0\n",
    "\n",
    "count_cols = ['RBI', 'SO', 'IBB', 'HBP', 'SH', 'SF']\n",
    "df_clean[count_cols] = df_clean[count_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to build a roster using OPS as a measure of offensive performance using current players, so using current data is important.  Let's use 2000 as our cutoff year, as current players will have debuted by then and we still have a big enough dataset for robust modeling.  We will also limit our data by defining a qualified hitter as a player with 125 or more at bats to avoid basing our conclusions on the smallest sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for modern baseball era\n",
    "df_clean = df_clean[df_clean['yearID'] >= 2000]\n",
    "\n",
    "# filter for qualified hitters\n",
    "df_clean = df_clean[df_clean['AB'] >= 125]\n",
    "\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the dataset size, columns, and that null values are removed\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 10,000+ records for robust modeling, they are modern era baseball records and contain many current players we can build our team around and/or target in trades or free agency!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate our target (OPS) and explore its relationship(s), if any, to our other data!  OPS is calculated as follows:\n",
    "OPS = OBP + SLG\n",
    "OBP is on-base percentage which measures how often a player gets on base (hits, walks, and hit by pitch).\n",
    "SLG is slugging percentage, which measures a hitter's power by dividing total bases by total at-bats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-engineering our target variable, OPS, and its components\n",
    "\n",
    "# calculate OBP or on-base percentage, avoid throwing data with division by zero\n",
    "numerator_obp = df_clean['H'] + df_clean['BB'] + df_clean['HBP']\n",
    "denominator_obp = df_clean['AB'] + df_clean['BB'] + df_clean['HBP'] + df_clean['SF']\n",
    "denominator_obp = denominator_obp.replace(0, np.nan) # avoid division by zero\n",
    "df_clean['OBP'] = numerator_obp / denominator_obp\n",
    "\n",
    "# calculate total bases\n",
    "df_clean['TB'] = (df_clean['H'] - df_clean['2B'] - df_clean['3B'] - df_clean['HR']) + (2 * df_clean['2B']) + (3 * df_clean['3B']) + (4 * df_clean['HR'])\n",
    "\n",
    "# calculate slugging percentage, avoid throwing data by dividing by zero\n",
    "df_clean['SLG'] = df_clean['TB'] / df_clean['AB'].replace(0, np.nan) # avoid division by zero\n",
    "\n",
    "# calculate OPS\n",
    "df_clean['OPS'] = df_clean['OBP'] + df_clean['SLG']\n",
    "df_clean['OPS'] = df_clean['OPS'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview target\n",
    "print(df_clean[['playerID', 'yearID', 'OPS']].head(60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acuna showing most seasons with an .800+ OPS looks about right!  These values make sense.  Now we're going to drop the variable columns containing raw stats which which feed into the calculation of OPS to avoid multicollinearity, because we already know those relationships exist.  We keep other features like R, RBI, SO, etc. for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify redundant columns\n",
    "ops_component_cols = ['AB', 'H', '2B', '3B', 'HR', 'BB', 'HBP', 'SF', 'TB', 'OBP', 'SLG']\n",
    "\n",
    "# drop redundant columns\n",
    "df_clean = df_clean.drop(columns=ops_component_cols, errors='ignore')\n",
    "\n",
    "# preview remaining data\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate some relationships between OPS and other remaining data.  Age is an important variable not contained in our data, so let's add that in from another CSV contained in the Lahman baseball database (People)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in People.csv\n",
    "people = pd.read_csv('lahman_1871-2024_csv/People.csv')\n",
    "\n",
    "#calculate age\n",
    "people['birthYear'] = people['birthYear'].fillna(0).astype(int)\n",
    "df_clean = pd.merge(df_clean, people[['playerID', 'birthYear']], on='playerID', how='left')\n",
    "df_clean['age'] = df_clean['yearID'] - df_clean['birthYear']\n",
    "df_clean['age'] = df_clean['age'].clip(18, 50) # clip outliers\n",
    "\n",
    "# drop birth year since we have age now\n",
    "df_clean = df_clean.drop(columns=['birthyear'], errors='ignore')\n",
    "\n",
    "# preview data containing age\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.sort_values(['playerID', 'yearID'])\n",
    "df_clean[\"OPS_next\"] = df_clean.groupby('playerID')['OPS'].shift(-1)\n",
    "\n",
    "df_train = df_clean[df_clean['yearID'] < 2024].dropna(subset=['OPS_next'])\n",
    "\n",
    "df_2024 = df_clean[df_clean['yearID'] == 2024].copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['R', 'RBI', 'SO', 'IBB', 'SH', 'age', 'OPS', 'OPS_next']\n",
    "corr_matrix = df_clean[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap of Key Features and OPS')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a notable lack of relationship between age and the other stats above, so let's investigate that further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot age vs. OPS\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('deep')\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.regplot(\n",
    "    x='age'\n",
    "    y='OPS'\n",
    "    data=df_clean\n",
    "    scatter_kws={'alpha': 0.4, 'color': 'skyblue', 's': 20}\n",
    "    line_kws={'color': 'navy', 'lw': 2},\n",
    "    lowess=True\n",
    ")\n",
    "\n",
    "age_means = df_clean.groupby('age')['OPS'].mean().reset_index()\n",
    "sns.scatterplot(\n",
    "    x='age'\n",
    "    y='OPS'\n",
    "    data=age_means,\n",
    "    color='orange',\n",
    "    s=100,\n",
    "    label='Mean OPS per Age'\n",
    ")\n",
    "\n",
    "plt.title('MLB Player Age vs. OPS')\n",
    "plt.xlabel('Player Age')\n",
    "plt.ylabel('OPS', fontsize=14)\n",
    "\n",
    "plt.xlim(18,45)\n",
    "\n",
    "peak_age = age_means.loc[age_means['OPS'].idxmax(), 'age']\n",
    "peak_OPS = age_means['OPS'].max()\n",
    "plt.annotate(\n",
    "    f'Peak at Age {int(peak_age)} (OPS: {peak_OPS:.3f})',\n",
    "    xy=(peak_age, peak_ops),\n",
    "    xytext=(peak_age + 2, peak_ops - 0.05),\n",
    "    arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
